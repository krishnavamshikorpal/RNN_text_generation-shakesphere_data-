{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn shakespeare.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPuY8UenMWBU"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from keras import Sequential,layers\n",
        "import pandas as pd\n",
        "import io\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqJ0mjItUjvD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f1da4cc-406e-4861-a663-a7eaefe77e94"
      },
      "source": [
        "a=\"hi@is!!be!\"\n",
        "print(a)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hi@is!!be!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kND0AtYSWSjv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed7fdb06-9f7d-4ef8-9ce5-c166b4e72131"
      },
      "source": [
        "print(repr(a))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'hi@is!!be!'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idZ9KmZkWjx2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89d1f476-2852-426d-8468-b5edb5396c03"
      },
      "source": [
        "path = tf.keras.utils.get_file(\"shakespeare.txt\", \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVupK4AUW9Qp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "911ab9ed-683c-491a-d1ac-e15cf378ad6d"
      },
      "source": [
        "path[:50]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.keras/datasets/shakespeare.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOByicfpXH2P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f0e4b4b-7889-45ed-be36-1a7d03e58496"
      },
      "source": [
        "text = open(path, \"rb\").read().decode(encoding=\"utf-8\")#utf-8 it is format which can understand any character\n",
        "print(\"{}\".format(len(text)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1115394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARMUW6IPYiZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cef11ceb-a287-49bb-86d0-2db87f7a3688"
      },
      "source": [
        "vocab = sorted(set(text))#set is a function which return the unique characters from data\n",
        "print(len(vocab))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhTpMVVSb_zf"
      },
      "source": [
        "char2id = {u:i for i, u in enumerate(vocab)}#giving the index to each unique character in data\n",
        "id2char = np.array(vocab)#converting the unique characters to an array\n",
        "text_as_int = np.array([char2id[c] for c in text])#giving the enumerate code to every charecter in the data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWBIdgWudo-P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57558ee5-293a-4a74-fc49-af0fa3f20a3c"
      },
      "source": [
        "seq_len = 100 #considering sequence length as 100\n",
        "examples = len(text)//(seq_len+1) \n",
        "#creating training examples\n",
        "train_examples = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "#printing from training_examples\n",
        "for i in train_examples.take(10):\n",
        "  print(type(i.numpy()))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.int64'>\n",
            "<class 'numpy.int64'>\n",
            "<class 'numpy.int64'>\n",
            "<class 'numpy.int64'>\n",
            "<class 'numpy.int64'>\n",
            "<class 'numpy.int64'>\n",
            "<class 'numpy.int64'>\n",
            "<class 'numpy.int64'>\n",
            "<class 'numpy.int64'>\n",
            "<class 'numpy.int64'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBGWcgDzfePK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee027e7-0b03-46e2-9de1-e25d52718d2f"
      },
      "source": [
        "#create batch examples\n",
        "sequences = train_examples.batch(seq_len+1, drop_remainder=True)\n",
        "\n",
        "for i in sequences.take(5):\n",
        "  #print(repr(i))\n",
        "  print(repr(\"\".join(id2char[i])))\n",
        "  "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZlTD7bNj0CU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce318fd5-48bc-4d8d-934d-f004772bf36d"
      },
      "source": [
        "#create labels and features\n",
        "\n",
        "def spli_input_target(example):\n",
        "  features = example[:-1]\n",
        "  target = example[1:]\n",
        "  return features, target\n",
        "\n",
        "dataset = sequences.map(spli_input_target)\n",
        "\n",
        "#print the labels and features\n",
        "\n",
        "for inp, out in dataset.take(1):\n",
        "  print(repr(\"\".join(id2char[inp])))\n",
        "  print(repr(\"\".join(id2char[out])))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG_JGAMD-9NW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69cad283-b567-4662-cb1e-9afb60394a74"
      },
      "source": [
        "Batch_size = 64\n",
        "Buffer_size = 10000\n",
        "\n",
        "#Each buffer size contains 100 batches and each batch size is 100 examples (example size is 101 characters)\n",
        "#Shuffling batches\n",
        "\n",
        "dataset = dataset.shuffle(Buffer_size).batch(Batch_size, drop_remainder=True)\n",
        "dataset"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7ntzeFfAO60"
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "emdb_dimension = 256\n",
        "rnn_units = 1024"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpI6bIT_MJQf"
      },
      "source": [
        "def build_model(vocab_size, dimension, rnn_units, batch_size):\n",
        "  model = Sequential()\n",
        "  model.add(layers.Embedding(vocab_size, dimension,batch_input_shape = [batch_size, None]))\n",
        "  model.add(layers.GRU(rnn_units, return_sequences=True, stateful=True,\n",
        "                       recurrent_initializer='glorot_uniform'))\n",
        "  model.add(layers.Dense(vocab_size))\n",
        "  return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPolEpMnP4QE"
      },
      "source": [
        "model = build_model(vocab_size=len(vocab), dimension=emdb_dimension, rnn_units=rnn_units, batch_size=Batch_size)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5_zfLD2QSya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a49669a1-f8b0-4cb8-da01-7f3655d9418f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv1tfoEVRHVz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7be0483d-7d12-4b50-cbe1-44f534c6307e"
      },
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  predictions = model(input_example)#predicting the values from 1st sequence input_example\n",
        "  print(predictions[1])\n",
        "  print(predictions.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-0.00343658 -0.01502991  0.0022298  ... -0.01276394  0.00417949\n",
            "   0.00989324]\n",
            " [-0.00728888 -0.00395077 -0.00139369 ... -0.01101313  0.01504948\n",
            "   0.00167927]\n",
            " [ 0.00326975  0.00152457  0.00484526 ... -0.00141118  0.01595432\n",
            "  -0.00357935]\n",
            " ...\n",
            " [ 0.00576745 -0.01077473  0.00603027 ...  0.00398898 -0.01472734\n",
            "  -0.0193965 ]\n",
            " [ 0.00919743 -0.00774173  0.00508142 ... -0.01038653 -0.00893181\n",
            "  -0.00537622]\n",
            " [-0.00772071  0.00947932 -0.00831406 ... -0.00982952 -0.01028185\n",
            "  -0.00449619]], shape=(100, 65), dtype=float32)\n",
            "(64, 100, 65)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cZ4GPymRr-c"
      },
      "source": [
        "sample_indices = tf.random.categorical(predictions[0], num_samples=1)\r\n",
        "sample_indices = tf.squeeze(sample_indices, axis = 1).numpy()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4JY4uhDSBPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f1a3c98-53c7-41c7-d69a-deac0a1833d8"
      },
      "source": [
        "print(\"input: \\n\", repr(\"\".join(id2char[input_example[0]])))\r\n",
        "print(\"Next Character: \\n\", repr(\"\".join(id2char[sample_indices])))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input: \n",
            " 'not where;\\nTo lie in cold obstruction and to rot;\\nThis sensible warm motion to become\\nA kneaded clod'\n",
            "Next Character: \n",
            " '3kLfMukopcJq&b, USZq3tbVWgPhTjYfN$, $,$DHRF:zvfu.XUhuno\\noDb-NwrLWKM3T:MGgkLqXRQweibyme&fOvhuccNeQpVF'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaSfTa2QXSTd",
        "outputId": "21451590-9358-4655-fb06-81948bafe6fd"
      },
      "source": [
        "def loss(labels, logits):\r\n",
        "   return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)#getting the loss function of the model\r\n",
        "\r\n",
        "loss_example = loss(target_example, predictions)\r\n",
        "print(\"prediction shape\", predictions.shape)\r\n",
        "print(\"scalar loss\", loss_example.numpy().mean())#return the mean loss of the model"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediction shape (64, 100, 65)\n",
            "scalar loss 4.1742067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLSh0bSaXWb5"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=loss)#compiling the model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFWoD_CsXdiq"
      },
      "source": [
        "#saving the weights of the model\r\n",
        "checkpoint_dir = \"./training_checkpoint\"\r\n",
        "\r\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\r\n",
        "\r\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only=True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_Z25XvPXiwM"
      },
      "source": [
        "EPOCHS = 5 #No. of epochs "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmT66KGkXmEp",
        "outputId": "a5fb47e9-d7f5-41c4-d83b-227658837499"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])#fitting the model"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "172/172 [==============================] - 12s 56ms/step - loss: 3.2100\n",
            "Epoch 2/5\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 2.0536\n",
            "Epoch 3/5\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 1.7459\n",
            "Epoch 4/5\n",
            "172/172 [==============================] - 11s 59ms/step - loss: 1.5723\n",
            "Epoch 5/5\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.4690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTKB63pBXom2"
      },
      "source": [
        "summary = history.history"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CazeW0L2XtCR",
        "outputId": "69b2e82b-de97-4b98-d2c2-fcbfa0d8d561"
      },
      "source": [
        "summary.keys()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "NSRQa_n1XtMc",
        "outputId": "325c9555-fb1e-4437-9661-1617111ed9a7"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "loss = summary['loss']\r\n",
        "epochs = range(1, 6)\r\n",
        "plt.plot(epochs, loss, 'p', label = \"Traning Loss values\")\r\n",
        "plt.title(\"LOSS\")\r\n",
        "plt.xlabel('Epochs')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.legend()\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ztoK14yfXtP7",
        "outputId": "e69f87eb-3fee-42e2-e719-6096261762ac"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./training_checkpoint/ckpt_5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRHL05f_X-UN"
      },
      "source": [
        "model = build_model(vocab_size, emdb_dimension, rnn_units, batch_size=1)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yg4JiQ7YBgS"
      },
      "source": [
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))#loading the weights which saved in checkppint_dir\r\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjFROaObYFvh",
        "outputId": "7416608a-7d25-4b2b-da52-5deebe6afd07"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 256)            16640     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, None, 65)             66625     \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCrPAiBlYIZU",
        "outputId": "972537de-c7e7-4ef4-b7c2-7bd94abaabff"
      },
      "source": [
        "input_eval = [12]\r\n",
        "print(input_eval)\r\n",
        "input_eval = tf.expand_dims(input_eval, 0)#here shape will be changed(previously-shape(1) now changed to (1, 1))\r\n",
        "print(input_eval)\r\n",
        "prediction = model(input_eval)#return the the 71 differnt character with there probabilty weights assigned\r\n",
        "print(prediction)\r\n",
        "prediction = tf.squeeze(prediction, 0)#squeeze the prediction values means it returns same values \r\n",
        "print(prediction)\r\n",
        "predicted_id = tf.random.categorical(prediction, num_samples=1)[-1, 0].numpy()\r\n",
        "print(predicted_id)#returns the highest probabilty weight from 71 different characters"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[12]\n",
            "tf.Tensor([[12]], shape=(1, 1), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[[10.254849    8.201426    2.5477593   0.03419755 -0.81719214\n",
            "    4.7891703   3.5829117   4.7018304   3.3419847   2.2931836\n",
            "    3.7552383   3.2689984   3.5843463  -0.70510477  0.4054444\n",
            "    0.2495133   0.15097906 -1.0598185   1.0429189   0.27328098\n",
            "   -1.5206938  -0.19402343 -1.8989271  -2.754269   -0.1541318\n",
            "   -0.9670357   3.246897    1.3802284  -0.7634143  -1.1568693\n",
            "   -0.3675018   0.98894954  0.85965496  0.5846894  -0.79588974\n",
            "    0.82223195  0.6172842   0.9098126   2.2646234  -3.630534\n",
            "   -2.000353   -3.465153   -1.6039696  -2.7946942  -0.7842995\n",
            "   -3.0532243  -5.007102   -2.7788677  -2.3243358  -2.7618005\n",
            "   -2.551947   -1.9066753  -1.6139352  -3.5937495  -2.366229\n",
            "   -3.3854504  -2.3266106  -2.422574   -2.5730433  -2.2372096\n",
            "   -1.7378685  -1.4545287  -1.485195   -1.3227812  -1.2175239 ]]], shape=(1, 1, 65), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[10.254849    8.201426    2.5477593   0.03419755 -0.81719214  4.7891703\n",
            "   3.5829117   4.7018304   3.3419847   2.2931836   3.7552383   3.2689984\n",
            "   3.5843463  -0.70510477  0.4054444   0.2495133   0.15097906 -1.0598185\n",
            "   1.0429189   0.27328098 -1.5206938  -0.19402343 -1.8989271  -2.754269\n",
            "  -0.1541318  -0.9670357   3.246897    1.3802284  -0.7634143  -1.1568693\n",
            "  -0.3675018   0.98894954  0.85965496  0.5846894  -0.79588974  0.82223195\n",
            "   0.6172842   0.9098126   2.2646234  -3.630534   -2.000353   -3.465153\n",
            "  -1.6039696  -2.7946942  -0.7842995  -3.0532243  -5.007102   -2.7788677\n",
            "  -2.3243358  -2.7618005  -2.551947   -1.9066753  -1.6139352  -3.5937495\n",
            "  -2.366229   -3.3854504  -2.3266106  -2.422574   -2.5730433  -2.2372096\n",
            "  -1.7378685  -1.4545287  -1.485195   -1.3227812  -1.2175239 ]], shape=(1, 65), dtype=float32)\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmK1vBz_YQAY"
      },
      "source": [
        "def generate_text(model, start_string):#generating the text through the model by giving the input(start_string)\r\n",
        "  num_generate = 500 #it will generate 500 text \r\n",
        "\r\n",
        "  input_eval = [char2id[d] for d in start_string]#Giving the unique index to each character in input string\r\n",
        "  input_eval = tf.expand_dims(input_eval, 0)#here shape will be changed\r\n",
        "\r\n",
        "  text_generated = []\r\n",
        "\r\n",
        "  temperature = 1\r\n",
        "  model.reset_states()\r\n",
        "  for i in range(num_generate):\r\n",
        "    prediction = model(input_eval)#so assigning  the input string to the model and getting the predictions\r\n",
        "    prediction = tf.squeeze(prediction, 0)#squeezing the predictions \r\n",
        "    prediction = prediction/temperature\r\n",
        "    predicted_id = tf.random.categorical(prediction, num_samples=1)[-1, 0].numpy()\r\n",
        "\r\n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\r\n",
        "    text_generated.append(id2char[predicted_id])\r\n",
        "  \r\n",
        "  return (start_string + \"\".join(text_generated))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74MUiCXFYWSh",
        "outputId": "d35d4d0e-31aa-4ca0-ba35-9e00f5420fa9"
      },
      "source": [
        "print(generate_text(model, \"Adam\")) #generating the text through the model by giving any input string"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adam, speak now to quitt that\n",
            "As I'll light! sir, cooment of.\n",
            "\n",
            "SICINIUS:\n",
            "May which sound thou MAlace: men, mowed Cupit you:\n",
            "You are herefore become thee shall yet own sovereign\n",
            "Truly, or enemy things him call in straigs to-makent\n",
            "Than I do ckt mine owher plapeth.\n",
            "I wound I love my further lesp of him:\n",
            "My humbler bow, I nume with my cousin?\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "O trid; or, I am poor purpose.\n",
            "\n",
            "GLOUCESTER:\n",
            "\n",
            "POLIXENES:\n",
            "Hark! Oft much be hence conrest thou, sort'ZAPHAP:\n",
            "Romeour mine.'\n",
            "\n",
            "ERCANIO:\n",
            "Therefore th\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yz2phaQnYjeb",
        "outputId": "513ce4a0-1c53-4316-94dc-33607c0eb471"
      },
      "source": [
        "!pip install pyspellchecker"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspellchecker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/9d/5bb403decde661abc6c5467319a0729d7c238e04d8217d9fef885510ec9d/pyspellchecker-0.5.6-py2.py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 8.5MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.5.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSk8PYm2Ynnk"
      },
      "source": [
        "from spellchecker import SpellChecker\r\n",
        "spell = SpellChecker()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QeZ-GyxYsxc"
      },
      "source": [
        "gen_text = generate_text(model,  u\"Someone: \")"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCDY08cyY0-k"
      },
      "source": [
        "ls_txt = gen_text.split()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OuxC_MRY4vF",
        "outputId": "287cda81-99ac-4b38-dd95-b8a61df6ddc1"
      },
      "source": [
        "#checking the accuracy of spellings predicted by model\r\n",
        "correct_words = spell.unknown(ls_txt)\r\n",
        "spell_acc = len(correct_words)/len(ls_txt)\r\n",
        "print(spell_acc)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.40404040404040403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9kw-s4tY7Xg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}